{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"SYN_SVHN_MNIST_domain_adap.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"SHgTI1Yfrw0g","colab":{}},"source":["%load_ext tensorboard\n","%tensorflow_version 2.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7SkPabep4xR-","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1588362694016,"user_tz":-120,"elapsed":7035,"user":{"displayName":"Linda Boedi","photoUrl":"","userId":"03818583902662567316"}},"outputId":"8022ce27-6eff-4419-d0bb-f718e188e30b"},"source":["from __future__ import print_function\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","from keras.datasets import mnist\n","import tensorflow_datasets as tfds\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.optimizers import RMSprop\n","from keras import backend as K\n","from scipy import ndimage\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import h5py\n","from skimage.transform import resize\n","from skimage.color import gray2rgb\n","from sklearn.utils import shuffle\n","\n","batch_size = 256\n","num_classes = 10\n","num_epochs = 10\n","val_size = 5000"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"to3kBbD3q1Wm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1588362694018,"user_tz":-120,"elapsed":6872,"user":{"displayName":"Linda Boedi","photoUrl":"","userId":"03818583902662567316"}},"outputId":"c35e207f-8043-42cf-c29d-f25eb41df115"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mh0u3Kx_rw1A","colab":{}},"source":["def load_data(path, val_size, num_classes):\n","    with h5py.File(path+'/train.hdf5', 'r') as f:\n","        shape = f[\"X\"].shape\n","        x_train = f[\"X\"][:shape[0]-val_size]\n","        y_train = f[\"Y\"][:shape[0]-val_size].flatten()\n","        x_val = f[\"X\"][shape[0]-val_size:]\n","        y_val = f[\"Y\"][shape[0] - val_size:].flatten()\n","\n","    with h5py.File(path+'/test.hdf5', 'r') as f:\n","        x_test = f[\"X\"][:]\n","        y_test = f[\"Y\"][:].flatten()\n","\n","    y_train = keras.utils.to_categorical(y_train, num_classes)\n","    y_val = keras.utils.to_categorical(y_val, num_classes)\n","    y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n","\n","def reshapeImages(images):\n","    images_redone = []\n","    for image in images:\n","        image = resize(image,(32,32))\n","        image = gray2rgb(image)\n","        images_redone.append(image)\n","    \n","    images = np.asarray(images_redone)\n","    images = images.reshape(images.shape[0], 32, 32, 3)\n","    images = images.astype('float32')\n","    images /= 255\n","    print(images.shape[0], 'samples')\n","    return (images)\n","\n","def show_history(history):\n","    plt.plot(history.history['acc'])\n","    plt.plot(history.history['val_acc'])\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train_accuracy', 'test_accuracy'], loc='best')\n","    plt.show()\n","    \n","def show_loss(history):\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model Loss')\n","    plt.ylabel('Loss')\n","    plt.xlabel('#f Iterations')\n","    plt.legend(['Train', 'Test'], loc='upper left')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsnafzGgqf8E","colab_type":"code","colab":{}},"source":["# the data, split between train and test sets\n","# The full `train` split and the full `test` split as two distinct datasets.\n","(x_train_svhn, y_train_svhn), (x_val_svhn, y_val_svhn), (x_test_svhn, y_test_svhn) = load_data('drive/My Drive/Data/svhn', val_size, num_classes)\n","(x_train_syn_orig, y_train_syn_orig), (x_val_syn, y_val_syn), (x_test_syn, y_test_syn) = load_data('drive/My Drive/Data/synthNumbers', val_size, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yxp76ls1gik8","colab_type":"code","colab":{}},"source":["y_train_syn_nrs = np.argmax(y_train_syn_orig, axis=-1)\n","y_train_svhn_nrs = np.argmax(y_train_svhn, axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mum_1ZFte5rU","colab_type":"code","colab":{}},"source":["nr_of_nrs_syn = 100\n","x_train_syn = x_train_syn_orig[y_train_syn_nrs == 0][:nr_of_nrs_syn]\n","y_train_syn = y_train_syn_orig[y_train_syn_nrs == 0][:nr_of_nrs_syn]\n","for i in range(1, 10):\n","  x_train_nr = x_train_syn_orig[y_train_syn_nrs == i][:nr_of_nrs_syn]\n","  y_train_nr = y_train_syn_orig[y_train_syn_nrs == i][:nr_of_nrs_syn]\n","  x_train_syn = np.vstack((x_train_syn, x_train_nr))\n","  y_train_syn = np.vstack((y_train_syn, y_train_nr))\n","  \n","x_train_syn, y_train_syn = shuffle(x_train_syn, y_train_syn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EwSktqT-rw1Z","colab":{"base_uri":"https://localhost:8080/","height":527},"executionInfo":{"status":"ok","timestamp":1588362766667,"user_tz":-120,"elapsed":77287,"user":{"displayName":"Linda Boedi","photoUrl":"","userId":"03818583902662567316"}},"outputId":"1ee6fa23-6603-486c-dbdc-957742089fb3"},"source":["input1 = keras.layers.Input(shape=(32,32,3))\n","conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu')(input1)\n","conv2 = keras.layers.Conv2D(32, (3, 3), activation='relu')(conv1)\n","maxpool1 = keras.layers.MaxPooling2D((2, 2))(conv2)\n","dropout1 = keras.layers.Dropout(0.1)(maxpool1)\n","conv3 = keras.layers.Conv2D(64, (3, 3), activation='relu')(dropout1)\n","conv4 = keras.layers.Conv2D(64, (3, 3), activation='relu')(conv3)\n","maxpool2 = keras.layers.MaxPooling2D((2, 2))(conv4)\n","flatten = keras.layers.Flatten()(maxpool2)\n","dense2 = keras.layers.Dense(512, activation='relu')(flatten)\n","output = keras.layers.Dense(num_classes, activation='softmax')(dense2)\n","\n","model = keras.Model(inputs=input1, outputs=[dense2,output])\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 30, 30, 32)        896       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1600)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 512)               819712    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                5130      \n","=================================================================\n","Total params: 890,410\n","Trainable params: 890,410\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8s8TU6uzVSci","colab_type":"code","colab":{}},"source":["y_train_svhn_zeros = np.zeros((y_train_svhn.shape[0],1))\n","y_train_svhn_ = np.hstack((y_train_svhn, y_train_svhn_zeros))\n","y_train_syn_ones = np.ones((y_train_syn.shape[0],1))\n","y_train_syn_ = np.hstack((y_train_syn, y_train_syn_ones))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"smS1TyOfrw1w","colab":{}},"source":["# Instantiate an optimizer to train the model.\n","optimizer = tf.compat.v1.train.AdamOptimizer()\n","# Instantiate a loss function.\n","loss_cc = keras.losses.CategoricalCrossentropy(from_logits=True)\n","\n","# Prepare the metrics.\n","train_acc_metric = keras.metrics.CategoricalAccuracy()\n","val_acc_metric = keras.metrics.CategoricalAccuracy()\n","\n","# Prepare the training datasets\n","train_dataset = tf.data.Dataset.from_tensor_slices((np.concatenate([x_train_svhn, x_train_syn], axis=0), np.concatenate([y_train_svhn_,y_train_syn_],axis=0)))\n","train_dataset = train_dataset.shuffle(buffer_size=100000).batch(batch_size)\n","\n","# Prepare the validation dataset.\n","val_dataset = tf.data.Dataset.from_tensor_slices((np.concatenate([x_val_svhn, x_val_syn], axis=0), np.concatenate([y_val_svhn,y_val_syn],axis=0)))\n","val_dataset = val_dataset.batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IOL7odVBkt6O","colab":{}},"source":["def distance_loss(predictions, y, predictions_target, y_target, classes_y):\n","    def some_function(tensor):\n","      y_source = tensor[1]\n","      equal =  tf.math.equal(y_source, y_target)\n","      equal_all = tf.reduce_all(equal, axis=1)\n","      contains = tf.boolean_mask(predictions_target, equal_all)\n","      distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(tensor[0], contains)), axis=1))\n","      # nearest k points\n","      closest_distance,_ = tf.math.top_k(tf.negative(distance), k=1)\n","      return tf.abs(closest_distance)\n","    y_equal_source =  tf.math.equal(classes_y, tf.constant(1, dtype=tf.float32))\n","    y_equal_all_source = tf.reduce_all(y_equal_source, axis=1)\n","    predictions_source = tf.boolean_mask(predictions, y_equal_all_source)\n","    y_source = tf.boolean_mask(y, y_equal_all_source)\n","    d = tf.map_fn(some_function, (predictions_source,y_source), dtype=tf.float32)\n","    return tf.math.reduce_sum(d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-A1kSKWpla8A","colab":{}},"source":["def train_step(model, optimizer, x_batch, y_batch, x_train_target, y_train_target, classes_y):\n","\n","    with tf.GradientTape() as tape:   \n","      hidden_logits = model(x_batch, training=True)[0]\n","      hidden_logits_target = model(x_train_target, training=True)[0]\n","      loss_dist = distance_loss(hidden_logits, y_batch, hidden_logits_target, y_train_target, classes_y)\n","      logits = model(x_batch, training=True)[1]\n","      loss_cross = loss_cc(y_batch, logits)\n","      loss_value = loss_cross + 0.00*loss_dist\n","\n","    grads = tape.gradient(loss_value, model.trainable_variables)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","    # Update training metric.\n","    train_acc_metric(y_batch, logits)\n","    return loss_value, loss_dist, loss_cross"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qRJ4zHPArw2Q","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1587744588215,"user_tz":-120,"elapsed":1668929,"user":{"displayName":"Linda Boedi","photoUrl":"","userId":"03818583902662567316"}},"outputId":"c48aff2e-fd93-4753-e1bc-91cdd274af65"},"source":["dist_losses = []\n","train_accuracy = []\n","cross_entropy_losses = []\n","val_accuracy = []\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    print('Start of epoch %d' % (epoch,))\n","    # Iterate over the batches of the dataset.\n","    step = 0\n","\n","    for (x_batch, y_batch) in train_dataset:\n","      \n","      classes_y = tf.cast(tf.strided_slice(tf.identity(y_batch), [0,-1], [y_batch.shape[0],y_batch.shape[0]], [1,1]),dtype=tf.float32)\n","      y_batch_ = tf.cast(tf.strided_slice(tf.identity(y_batch), [0,0], [y_batch.shape[0],-1], [1,1]),dtype=tf.float32)\n","\n","      loss_value, loss_dist, loss_cross = train_step(model, optimizer, x_batch, y_batch_, tf.constant(x_train_svhn, dtype=tf.float32), tf.constant(y_train_svhn, dtype=tf.float32), classes_y)\n","\n","      # Log every 250 batches.\n","      if step % 250 == 0:\n","        print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n","        print('Distance loss and cross entropy loss at step %s: %s  %s' % (step, float(loss_dist),float(loss_cross)))\n","\n","      step +=1\n","    \n","    dist_losses.append(float(loss_dist))\n","    cross_entropy_losses.append(float(loss_cross))\n","\n","    # Display metrics at the end of each epoch.\n","    train_acc = train_acc_metric.result()\n","    print('Training acc over epoch: %s' % (float(train_acc),))\n","    train_accuracy.append(float(train_acc))\n","\n","    # Run a validation loop at the end of each epoch.\n","    for x_batch_val, y_batch_val in val_dataset:\n","        val_logits = model(x_batch_val)[1]\n","        # Update val metrics\n","        val_acc_metric(y_batch_val, val_logits)\n","    val_acc = val_acc_metric.result()\n","    print('Validation acc: %s' % (float(val_acc),))\n","    val_accuracy.append(float(val_acc))\n","\n","    # Reset training metrics at the end of each epoch\n","    train_acc_metric.reset_states()\n","    val_acc_metric.reset_states()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Start of epoch 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OpRQwEF_rw3M","colab":{}},"source":["plt.plot(dist_losses)\n","plt.plot(cross_entropy_losses)\n","plt.ylabel('loss')\n","plt.xlabel('batches')\n","plt.legend(['dist_loss', 'cross_entropy_loss'], loc='best')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"chLLKD2zABU_","colab":{}},"source":["plt.plot(cross_entropy_losses)\n","plt.ylabel('loss')\n","plt.xlabel('batches')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F6YUrvTzrw3R","colab":{}},"source":["plt.plot(train_accuracy)\n","plt.ylabel('accuracy')\n","plt.xlabel('epochs')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bhGhSWtlw0Nr","colab_type":"code","colab":{}},"source":["(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()\n","x_test_mnist = reshapeImages(x_test_mnist)\n","\n","# convert class vectors to binary class matrices\n","y_test_mnist = keras.utils.to_categorical(y_test_mnist, num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fo8yUOiIrw3o","colab":{}},"source":["model_new = keras.models.clone_model(model)\n","model_new.set_weights(model.get_weights()) \n","\n","model_new._layers.pop()\n","for layer in model_new.layers: layer.trainable = False  \n","\n","# recover the output from the last layer in the model and use as input to new Dense layer\n","last = model_new.layers[-1].output\n","output = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(last)\n","model_new = keras.models.Model(model_new.input, output)\n","\n","for layer in model_new.layers:\n","    print(layer, layer.trainable)\n","\n","model_new.compile(loss='categorical_crossentropy',\n","              optimizer='Adam',\n","              metrics=['accuracy'])\n","\n","model_new.summary()\n","\n","history = model_new.fit(x_train_svhn, y_train_svhn , val_data = (x_val_svhn, y_val_svhn), epochs=15,\n","    shuffle=True,\n","    verbose=1)\n","\n","score = model_new.evaluate(x_test_mnist, y_test_mnist, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cBLAOL_Yrw3u","colab":{}},"source":["plt.plot(history.history['accuracy'])\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train_accuracy'], loc='best')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8NYTWF6BeaI1","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}